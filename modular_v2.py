# -*- coding: utf-8 -*-
"""MODULAR_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IZYfLsU8VYN8zxS7CfFqr7NtJnCUleY-
"""

# Import necessary libraries
import requests  # For downloading dataset
import pandas as pd  # For handling data
import sklearn.metrics  # For evaluating model performance

from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
from zipfile import ZipFile
import math

import keras
from keras import layers
from keras import ops

from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from sklearn.metrics import mean_squared_error, mean_absolute_error

from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS
from pyspark.sql.functions import lit
from pyspark.sql.types import StructType, StructField, IntegerType, FloatType

from sklearn.metrics.pairwise import cosine_similarity

import random

class IDIndexMapper:
    def __init__(self, ratings_df):
        """
        Initializes the mapper with dictionaries for encoding and decoding based on a given DataFrame.

        Args:
            ratings_df (pd.DataFrame): A DataFrame containing 'userId' and 'movieId' columns.
        """
        self.user_id_to_index_map = {}
        self.user_index_to_id_map = {}
        self.movie_id_to_index_map = {}
        self.movie_index_to_id_map = {}
        self.next_user_index = 0
        self.next_movie_index = 0

        # Create mappings for user IDs and movie IDs
        self._initialize_mappings(ratings_df)

    def _initialize_mappings(self, ratings_df):
        """
        Generates initial mappings for user IDs and movie IDs from the DataFrame based on their order of appearance.

        Args:
            ratings_df (pd.DataFrame): A DataFrame containing 'userId' and 'movieId' columns.
        """
        for user_id in ratings_df['userId']:  # Assign indices for user IDs in order of appearance
            if user_id not in self.user_id_to_index_map:
                self.user_id_to_index_map[user_id] = self.next_user_index
                self.user_index_to_id_map[self.next_user_index] = user_id
                self.next_user_index += 1
        for movie_id in ratings_df['movieId']:  # Assign indices for movie IDs in order of appearance
            if movie_id not in self.movie_id_to_index_map:
                self.movie_id_to_index_map[movie_id] = self.next_movie_index
                self.movie_index_to_id_map[self.next_movie_index] = movie_id
                self.next_movie_index += 1

    def id_to_index(self, id_, id_type, from_add_new_id=False):
        """
        Encodes an ID to a sequential index. A new index is assigned only if called from add_new_id.

        Args:
            id_ (int or str): The original ID (e.g., user ID or movie ID).
            id_type (str): The type of ID ('user' or 'movie').
            from_add_new_id (bool): Flag indicating if the call is from add_new_id.

        Returns:
            int: The corresponding sequential index.
        """
        if id_type == 'user':
            if id_ not in self.user_id_to_index_map:
                if from_add_new_id:
                    self.user_id_to_index_map[id_] = self.next_user_index
                    self.user_index_to_id_map[self.next_user_index] = id_
                    self.next_user_index += 1
                else:
                    raise KeyError(f"User ID {id_} is not mapped.")
            return self.user_id_to_index_map[id_]
        elif id_type == 'movie':
            if id_ not in self.movie_id_to_index_map:
                if from_add_new_id:
                    self.movie_id_to_index_map[id_] = self.next_movie_index
                    self.movie_index_to_id_map[self.next_movie_index] = id_
                    self.next_movie_index += 1
                else:
                    raise KeyError(f"Movie ID {id_} is not mapped.")
            return self.movie_id_to_index_map[id_]
        else:
            raise ValueError("id_type must be either 'user' or 'movie'")

    def index_to_id(self, index, id_type):
        """
        Decodes a sequential index back to the original ID.

        Args:
            index (int): The sequential index.
            id_type (str): The type of ID ('user' or 'movie').

        Returns:
            int or str: The original ID corresponding to the index.

        Raises:
            KeyError: If the index is not found in the mapping.
        """
        if id_type == 'user':
            if index not in self.user_index_to_id_map:
                raise KeyError(f"User index {index} not found in mapping.")
            return self.user_index_to_id_map[index]
        elif id_type == 'movie':
            if index not in self.movie_index_to_id_map:
                raise KeyError(f"Movie index {index} not found in mapping.")
            return self.movie_index_to_id_map[index]
        else:
            raise ValueError("id_type must be either 'user' or 'movie'")

    def add_new_id(self, id_type):
        """
        Allocates a random ID that is not already occupied, maps it, and returns it.

        Args:
            id_type (str): The type of ID ('user' or 'movie').

        Returns:
            int: The newly allocated random ID.
        """
        new_id = None
        if id_type == 'user':
            while True:
                new_id = random.randint(1, 1_000_000)
                if new_id not in self.user_id_to_index_map:
                    break
            self.user_id_to_index_map[new_id] = self.next_user_index
            self.user_index_to_id_map[self.next_user_index] = new_id
            self.next_user_index += 1
        elif id_type == 'movie':
            while True:
                new_id = random.randint(1, 1_000_000)
                if new_id not in self.movie_id_to_index_map:
                    break
            self.movie_id_to_index_map[new_id] = self.next_movie_index
            self.movie_index_to_id_map[self.next_movie_index] = new_id
            self.next_movie_index += 1
        else:
            raise ValueError("id_type must be either 'user' or 'movie'")

        return new_id


    def get_mappings(self):
        """
        Returns the current mappings for debugging or exporting purposes.

        Returns:
            dict: A dictionary containing user and movie mappings.
        """
        return {
            'user_id_to_index_map': self.user_id_to_index_map,
            'user_index_to_id_map': self.user_index_to_id_map,
            'movie_id_to_index_map': self.movie_id_to_index_map,
            'movie_index_to_id_map': self.movie_index_to_id_map
        }

class DataIngestion:
    def __init__(self):
      return

    def download_data(self):
        movie_df = pd.read_csv('movie_df_AFTER_FEAT_ENG.csv')
        ratings_df = pd.read_csv('ratingsfullclean.csv')
        movie_titles = pd.read_csv('moviefullclean.csv').drop(columns=["genres","imdbId","tmdbId","most_popular_cast","director","original_language","overview","popularity","release_date","poster_path","vote_average"])

        mapper = IDIndexMapper(ratings_df)

        return ratings_df, movie_df, movie_titles, mapper

class ContentBasedModel:
    def __init__(self):
        self.df_user = None
        self.cluster_centroids = None
        self.movie_group_dict = None
        self.optimal_k = 5

    def train(self, ratings_df, movie_df):
        print("Training Content Based Model...")
        # Step 1: Merge ratings_df with movie_df on movieId
        merged_df = ratings_df.merge(movie_df, on='movieId')

        # Step 2: Multiply features by the rating
        feature_columns = [col for col in movie_df.columns if col != 'movieId']
        for feature in feature_columns:
            merged_df[feature] = merged_df[feature] * merged_df['rating']

        # Step 3: Group by userId and sum across features
        user_features = merged_df.groupby('userId')[feature_columns].sum().reset_index()

        self.df_user = pd.concat([user_features[['userId']], user_features[feature_columns]], axis=1)

        kmeans = KMeans(n_clusters=self.optimal_k, random_state=42)
        movie_groups = kmeans.fit_predict(movie_df.drop(columns=['movieId'], errors='ignore'))

        # Create dictionary mapping movieId to movie_group
        self.movie_group_dict = dict(zip(movie_df['movieId'], movie_groups))

        self.cluster_centroids = kmeans.cluster_centers_

        return

    def recommend(self, user_id, ratings_df, movie_df, N_recommendation=10):
        print("Recommending for user (CB)...")

        # Step 1: Get the user profile
        user_profile = self.df_user[self.df_user['userId'] == user_id].drop(columns=['userId']).values.reshape(1, -1)

        # Step 2: Compute similarity between user profile and cluster centroids
        centroid_similarity_scores = cosine_similarity(user_profile, self.cluster_centroids).flatten()

        # Step 3: Identify the most similar cluster
        most_similar_cluster = np.argmax(centroid_similarity_scores)

        # Step 4: Get movies in the most similar cluster
        movies_in_cluster_ids = [movie_id for movie_id, group in self.movie_group_dict.items() if group == most_similar_cluster]
        movies_in_cluster = movie_df[movie_df['movieId'].isin(movies_in_cluster_ids)]

        # Step 5: Filter out movies already seen by the user BEFORE computing similarity
        seen_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].tolist()
        movies_in_cluster = movies_in_cluster[~movies_in_cluster['movieId'].isin(seen_movies)]

        # Step 6: Compute similarity with movies in the selected cluster (excluding already seen movies)
        movie_features_in_cluster = movies_in_cluster.drop(columns=['movieId']).values
        similarity_scores = cosine_similarity(user_profile, movie_features_in_cluster).flatten()

        # Step 7: Create a DataFrame with similarity scores
        movie_similarity = pd.DataFrame({
            'movieId': movies_in_cluster['movieId'].values,
            'prediction': similarity_scores
        })

        # Step 8: Get top recommendations
        content_based_recommendation = movie_similarity.sort_values(by='prediction', ascending=False).head(N_recommendation)

        return content_based_recommendation

    def update_content_based(self, user_id, movie_id, rating, movie_df):
        """
        Updates the user vector in df_user with new feedback.

        Args:
            df_user (pd.DataFrame): Current user feature vectors.
            new_rating (dict): A dictionary with keys 'userId', 'movieId', and 'rating'.
            movie_df (pd.DataFrame): Movie features dataframe.

        Returns:
            pd.DataFrame: Updated df_user with normalized user vector.
        """

        # Get the feature vector for the rated movie
        movie_features = movie_df[movie_df['movieId'] == movie_id].iloc[0]
        feature_columns = [col for col in movie_df.columns if col not in ['movieId']]
        movie_vector = movie_features[feature_columns].values

        # Scale the movie vector by the rating
        scaled_vector = movie_vector * rating

        # Find the user's existing vector
        user_index = self.df_user[self.df_user['userId'] == user_id].index[0]
        user_vector = self.df_user.loc[user_index, feature_columns].values

        # Update the user vector
        updated_vector = user_vector + scaled_vector

        # Update the dataframe with the new vector
        self.df_user.loc[user_index, feature_columns] = updated_vector

    def initialize_user_profile(self, user_id, liked_movies, movie_df, ratings=None):
        """
        Initializes a new user vector for a cold start user based on liked movies.

        Args:
            user_id (int): ID of the new user.
            liked_movies (list): List of movieIds the user liked.
            movie_df (pd.DataFrame): DataFrame containing movie features.
            ratings (list, optional): List of ratings corresponding to liked_movies. If provided, these will replace the default scaling factor.
        """

        # Get the feature columns
        feature_columns = [col for col in movie_df.columns if col not in ['movieId']]

        # Initialize user vector with zeros
        user_vector = np.zeros(len(feature_columns))

        # Add scaled vectors for liked movies
        for idx, movie_id in enumerate(liked_movies):
            movie_features = movie_df[movie_df['movieId'] == movie_id][feature_columns].values
            if movie_features.size > 0:  # Ensure the movie exists in the dataset
                scaling_factor = ratings[idx] if ratings else 5  # Use provided rating or default to 5
                user_vector += movie_features.flatten() * scaling_factor

        # Normalize the vector (optional, depending on your use case)
        user_vector = user_vector / np.linalg.norm(user_vector)

        # Append the new user vector to df_user
        new_user_row = pd.DataFrame([[user_id] + user_vector.tolist()], columns=['userId'] + feature_columns)
        self.df_user = pd.concat([self.df_user, new_user_row], ignore_index=True)

class CollaborativeBasedModel:
    def __init__(self, maxIter = 10, regParam = 0.1, rank = 10):
        self.model = None
        self.data = None
        self.maxIter = maxIter
        self.regParam = regParam
        self.rank = rank
        self.cluster_centroids = None
        self.movie_group_dict = None
        self.optimal_k = 5
        self.movie_factors_df = None
        self.user_factors_df = None
        self.spark = None

    def train(self, ratings_df, mapper):
        print("Training Collaborative Based Model...")

        self.spark = SparkSession.builder \
            .appName("ALS Example") \
            .getOrCreate()

        # Extract necessary mappings using the mapper
        user_indices = ratings_df['userId'].apply(lambda x: mapper.id_to_index(x, 'user')).tolist()
        movie_indices = ratings_df['movieId'].apply(lambda x: mapper.id_to_index(x, 'movie')).tolist()
        ratings = ratings_df['rating'].tolist()

        data_with_indices = list(zip(user_indices, movie_indices, ratings))

        # Define schema for Spark DataFrame
        schema = StructType([
            StructField("userIndex", IntegerType(), True),
            StructField("movieIndex", IntegerType(), True),
            StructField("rating", FloatType(), True)
        ])

        # Step 3: Create Spark DataFrame
        self.data = self.spark.createDataFrame(data_with_indices, schema=schema)

        als = ALS(
            maxIter=self.maxIter,
            regParam=self.regParam,
            rank=self.rank,
            userCol="userIndex",
            itemCol="movieIndex",
            ratingCol="rating",
            coldStartStrategy="drop"
        )

        self.model = als.fit(self.data)

        # Save user and movie factors
        self.movie_factors = self.model.itemFactors.toPandas()
        self.user_factors = self.model.userFactors.toPandas()

        # Convert movie factors to a dictionary for clustering
        features = np.array(self.movie_factors['features'].tolist())

        # Perform KMeans clustering
        kmeans = KMeans(n_clusters=self.optimal_k, random_state=42)
        kmeans.fit(features)

        self.movie_factors['cluster'] = kmeans.labels_
        self.movie_group_dict = dict(zip(self.movie_factors['id'], self.movie_factors['cluster']))

        self.cluster_centroids = kmeans.cluster_centers_


    def recommend(self, user_id, ratings_df, mapper):
        print("Recommending for user (CFB)...")
        try:
            target_user_index = mapper.id_to_index(user_id, 'user')
        except KeyError:
            print(f"UserId {user_id} has no mappings!")
            return None

        # Check if the target_user_index is in user_factors
        if target_user_index not in self.user_factors['id'].values:
            return None

        target_user_vector = np.array(self.user_factors.loc[self.user_factors['id'] == target_user_index, 'features'].iloc[0])

        # Step 1: Compute dot products with centroids
        centroid_similarities = [np.dot(target_user_vector, centroid) for centroid in self.cluster_centroids]
        target_cluster = np.argmax(centroid_similarities)

        # Step 2: Filter movies in the target cluster
        cluster_movies = self.movie_factors[self.movie_factors['cluster'] == target_cluster]

        # Step 3: Exclude seen movies
        seen_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].apply(lambda x: mapper.id_to_index(x, 'movie')).tolist()
        unseen_movies = cluster_movies[~cluster_movies['id'].isin(seen_movies)].copy()

        # Step 4: Compute dot product for movies in the target cluster
        unseen_movies.loc[:, 'prediction'] = unseen_movies['features'].apply(lambda x: np.dot(target_user_vector, np.array(x)))

        # Step 5: Get top recommendations
        recommendations = unseen_movies.sort_values('prediction', ascending=False).head(10)
        recommendations['movieId'] = recommendations['id'].apply(lambda x: mapper.index_to_id(x, 'movie'))

        return recommendations[['movieId', 'prediction']]


    def update_collaborative_based(self, user_id, movie_id, rating, mapper, learning_rate=0.01):

        user_index = mapper.id_to_index(user_id, 'user')
        movie_index = mapper.id_to_index(movie_id, 'movie')

        if user_index not in self.user_factors['id'].values:
            return

        user_row = self.user_factors.loc[self.user_factors['id'] == user_index].index[0]
        movie_row = self.movie_factors.loc[self.movie_factors['id'] == movie_index].index[0]

        user_vector = np.array(self.user_factors.at[user_row, 'features'])
        movie_vector = np.array(self.movie_factors.at[movie_row, 'features'])

        error = rating - np.dot(user_vector, movie_vector)

        # Update factors
        self.user_factors.at[user_row, 'features'] = user_vector + learning_rate * error * movie_vector
        self.movie_factors.at[movie_row, 'features'] = movie_vector + learning_rate * error * user_vector

class HybridModel:
    def __init__(self):
        self.content_based_model = ContentBasedModel()
        self.collaborative_based_model = CollaborativeBasedModel()
        self.alpha_dict = {}
        self.user_movie_sources = {}

    def train(self, ratings_df, movie_df, mapper):
        self.content_based_model.train(ratings_df, movie_df)
        self.collaborative_based_model.train(ratings_df, mapper)

    def recommend(self, user_id, ratings_df, movie_df, mapper):
        # Check if user_id exists in alpha_dict, if not, initialize it with 0.5
        if user_id not in self.alpha_dict:
            self.alpha_dict[user_id] = 0.5

        # Weighting factors
        alpha = self.alpha_dict[user_id]
        beta = 1 - alpha

        # Get recommendations from both models
        content_recommendation = self.content_based_model.recommend(user_id, ratings_df, movie_df)
        content_recommendation['source'] = 'CB'

        collaborative_recommendation = self.collaborative_based_model.recommend(user_id, ratings_df, mapper)
        # Cold start users only get content_recommendation
        if collaborative_recommendation is None:
          return content_recommendation.head(10)

        collaborative_recommendation['source'] = 'CFB'

        # Remove overlapping movies by keeping content-based recommendations
        common_movies = set(content_recommendation['movieId']).intersection(set(collaborative_recommendation['movieId']))
        collaborative_recommendation = collaborative_recommendation[~collaborative_recommendation['movieId'].isin(common_movies)]

        # Combine the two recommendations
        combined_recommendation = pd.concat([
            content_recommendation.head(int(alpha * len(content_recommendation))),
            collaborative_recommendation.head(int(beta * len(collaborative_recommendation)))
        ])

        # Remove duplicates by keeping the higher priority source
        combined_recommendation = combined_recommendation.reset_index(drop=True)

        # Store movieId and their source in a dictionary
        self.user_movie_sources[user_id] = dict(zip(combined_recommendation['movieId'], combined_recommendation['source']))
        return combined_recommendation

    def cold_user_start(self, user_id, liked_movies, movie_df, ratings=None):
        self.content_based_model.initialize_user_profile(user_id, liked_movies, movie_df, ratings)

class MLPipeline:
    def __init__(self):
        self.data_ingestion = DataIngestion()
        self.hybrid_model = HybridModel()
        self.feedback_model = Feedback()
        self.cold_start = None
        self.mapper = None

        self.ratings_df = None
        self.movie_df = None
        self.movie_titles = None

    def build_pipeline(self):
        print("Downloading and loading data...")
        self.ratings_df, self.movie_df, self.movie_titles, self.mapper = self.data_ingestion.download_data()
        self.cold_start = ColdStartStrategy(self.ratings_df)
        self.hybrid_model.train(self.ratings_df, self.movie_df, self.mapper)


    def recommend(self, user_id):
        if user_id in self.cold_start.cold_users_movies:
          if len(self.cold_start.cold_users_movies[user_id]) == 5:
            self.hybrid_model.cold_user_start(user_id, self.cold_start.cold_users_movies[user_id], self.movie_df, self.cold_start.cold_users_ratings[user_id])
            self.cold_star.warm_user(user_id)
          else:
            recommendation = self.cold_start.popular_movies[:10]
        else:
          recommendation = self.hybrid_model.recommend(user_id, self.ratings_df, self.movie_df, self.mapper)

        print(recommendation)

    def feedback(self, user_id, movie_id, rating):
        if user_id in self.cold_start.cold_users_movies:
          self.ratings_df = self.cold_start.cold_feedback(user_id, movie_id, rating, self.ratings_df)
        else:
          self.ratings_df = self.feedback_model.feedback(user_id, movie_id, rating, self.movie_df, self.hybrid_model, self.ratings_df, self.mapper)

    def create_user(self):
        return self.mapper.add_new_id('user')

    def form_user(self, user_id, liked_movies=None):
        if liked_movies is None:
          self.cold_start.user(user_id)
        else:
          self.hybrid_model.cold_user_start(user_id, liked_movies, self.movie_df)

class ColdStartStrategy():
      def __init__(self, ratings_df):
          self.popular_movies = self._get_popular_movies(ratings_df)
          self.cold_users_movies = {}
          self.cold_users_ratings = {}

      def _get_popular_movies(self, ratings_df):
          movie_scores = ratings_df.groupby('movieId').agg(
              popularity=('rating', 'count'),
              likeability=('rating', 'mean')
          ).assign(
              popularity_likeability_score=lambda x: x['popularity'] * 0.5 + x['likeability'] * 0.5
          ).sort_values(by='popularity_likeability_score', ascending=False).reset_index()

          return movie_scores.movieId.head(20).values

      def user(self, user_id):
        self.cold_users_movies[user_id] = []
        self.cold_users_ratings[user_id] = []

      def cold_feedback(self, user_id, movie_id, rating, ratings_df):
        """
        Adds the movie and its rating to the cold user's feedback and updates the ratings dataframe.

        Args:
            user_id (int): ID of the cold user.
            movie_id (int): ID of the movie the user is rating.
            rating (float): Rating given by the user.
            ratings_df (pd.DataFrame): The ratings DataFrame to update.

        Returns:
            pd.DataFrame: Updated ratings DataFrame.
        """
        # Add the movie and rating to the respective dictionaries
        self.cold_users_movies[user_id].append(movie_id)
        self.cold_users_ratings[user_id].append(rating)

        # Create a new row for the ratings DataFrame
        new_row = pd.DataFrame({
            'userId': [user_id],
            'movieId': [movie_id],
            'rating': [rating]
        })

        # Concatenate the new row to the ratings DataFrame
        ratings_df = pd.concat([ratings_df, new_row], ignore_index=True)

        return ratings_df

      def warm_user(self, user_id):
        """
        Deletes the user_id from the cold start dictionaries.

        Args:
            user_id (int): ID of the user to remove.
        """
        if user_id in self.cold_users_movies:
            del self.cold_users_movies[user_id]
        if user_id in self.cold_users_ratings:
            del self.cold_users_ratings[user_id]

class Feedback:
    def __init__(self):
        pass

    def feedback(self, user_id, movie_id, rating, movie_df, hybrid_model, ratings_df, mapper):
        print("Processing Feedback...")

        # Update models
        hybrid_model.content_based_model.update_content_based(user_id, movie_id, rating, movie_df)
        hybrid_model.collaborative_based_model.update_collaborative_based(user_id, movie_id, rating, mapper)

        # Update the ratings dataframe
        new_row = {'userId': [user_id], 'movieId': [movie_id], 'rating': [rating]}
        new_row_df = pd.DataFrame(new_row)
        ratings_df = pd.concat([ratings_df, new_row_df], ignore_index=True)

        # Access alpha_dict and user_movie_sources from the hybrid model
        alpha_dict = hybrid_model.alpha_dict
        user_movie_sources = hybrid_model.user_movie_sources

        # Ensure user_id exists in alpha_dict
        if user_id not in alpha_dict:
            alpha_dict[user_id] = 0.5

        # Adjust alpha_dict[user_id] based on the rating and source
        if user_id in user_movie_sources and movie_id in user_movie_sources[user_id]:
            source = user_movie_sources[user_id][movie_id]

            if rating >= 3:
                if source == 'CB':
                    alpha_dict[user_id] = round(min(0.8, alpha_dict[user_id] + 0.1), 1)
                elif source == 'CFB':
                    alpha_dict[user_id] = round(max(0.2, alpha_dict[user_id] - 0.1), 1)
            else:
                if source == 'CB':
                    alpha_dict[user_id] = round(max(0.2, alpha_dict[user_id] - 0.1), 1)
                elif source == 'CFB':
                    alpha_dict[user_id] = round(min(0.8, alpha_dict[user_id] + 0.1), 1)

        return ratings_df

def main():
    pipeline = MLPipeline()
    pipeline.build_pipeline()
    while True:
        user_input = int(input("Enter a value (negative to exit): "))
        if user_input < 0:
            print("Exiting...")
            break
        pipeline.recommend(user_input)

        user_id = user_input
        movie_id = int(input("Enter a value for movie_id: "))
        rating = int(input("Enter a value for rating: "))
        pipeline.feedback(user_id, movie_id, rating)

# Run the main system
main()













